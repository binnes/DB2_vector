{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from ibm_watsonx_ai import APIClient, Credentials\n",
    "from ibm_watsonx_ai.foundation_models import Embeddings\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "\n",
    "ont_cities = [\n",
    "    \"Toronto\", \"Ottawa\"\n",
    "]\n",
    "\n",
    "# Definitions\n",
    "brands = ['Zentrax', 'FootFlex', 'StrideOne', 'Loopic', 'RunXpress']\n",
    "types = ['Running', 'Walking']\n",
    "classes = ['Men', 'Women']\n",
    "materials = ['Synthetic', 'Knit']\n",
    "colors = ['Black', 'White']\n",
    "arch_supports = ['High', 'Flat']\n",
    "weather_resistances = ['Waterproof', 'Resistant']\n",
    "sizes = [round(s, 1) for s in range(6, 13)] + [s + 0.5 for s in range(6, 13)]\n",
    "store_ids = range(1, 21)\n",
    "\n",
    "# Helper: create a fake product name\n",
    "def create_product_name(brand, shoe_type):\n",
    "    return f\"{brand} {random.choice(['Ultra', 'Flex', 'Pro', 'X', 'Max'])} {shoe_type}\"\n",
    "\n",
    "# Helper: create fake keywords\n",
    "def generate_keywords(shoe_type, material):\n",
    "    keywords = [shoe_type.lower(), material.lower()]\n",
    "    keywords += random.sample(['lightweight', 'durable', 'breathable', 'cushioned', 'supportive', 'flexible'], 3)\n",
    "    return ', '.join(keywords)\n",
    "\n",
    "def generate_shoe_data(n=500):\n",
    "    data = []\n",
    "    used_skus = set()\n",
    "\n",
    "    for _ in range(n):\n",
    "        brand = random.choice(brands)\n",
    "        shoe_type = random.choice(types)\n",
    "        shoe_class = random.choice(classes)\n",
    "        material = random.choice(materials)\n",
    "        size = random.choice(sizes)\n",
    "        color = random.choice(colors)\n",
    "        arch = random.choice(arch_supports)\n",
    "        weather = random.choice(weather_resistances)\n",
    "        store_id = random.choice(store_ids)\n",
    "        city = random.choice(ont_cities)\n",
    "                \n",
    "        price = round(random.uniform(29.99, 149.99), 2)\n",
    "        rating = round(random.uniform(3.0, 5.0), 1)\n",
    "        product_name = create_product_name(brand, shoe_type)\n",
    "\n",
    "        # Ensure SKU uniqueness\n",
    "        while True:\n",
    "            sku = f\"{brand[:3].upper()}-{random.randint(1000, 9999)}\"\n",
    "            if sku not in used_skus:\n",
    "                used_skus.add(sku)\n",
    "                break\n",
    "\n",
    "        data.append({\n",
    "            'SKU': sku,\n",
    "            'PRODUCT_NAME': product_name,\n",
    "            'BRAND': brand,\n",
    "            'CLASS': shoe_class,\n",
    "            'TYPE': shoe_type,\n",
    "            'MATERIAL': material,\n",
    "            'COLOR': color,\n",
    "            'WEATHER_RESISTANCE': weather,\n",
    "            'ARCH_SUPPORT': arch,\n",
    "            'SIZE': size,\n",
    "            'PRICE': price,\n",
    "            'RATING': rating,\n",
    "            'STORE_ID': store_id,\n",
    "            'CITY': city\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate and save\n",
    "df_shoes = generate_shoe_data(500)\n",
    "# sq_shoes.to_csv(\"shoes.csv\", index=False)\n",
    "# print(\"Dataset saved as 'shoes.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shoes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_cols = ['TYPE', 'MATERIAL', 'COLOR', 'WEATHER_RESISTANCE', 'ARCH_SUPPORT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shoes[embedding_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating embedding vetors for the shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all embedding columns into a single string for each row, including column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shoes['COMBINED'] = df_shoes.apply(\n",
    "    lambda row: ' [SEP] '.join([f\"{col_name}: {row[col_name]}\" for col_name in embedding_cols]), \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_show = ['TYPE', 'MATERIAL', 'COLOR', 'WEATHER_RESISTANCE', 'ARCH_SUPPORT', 'COMBINED']\n",
    "df_shoes[cols_to_show].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shoes.iloc[0]['COMBINED']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up `wx.ai` embedding API connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(os.getcwd()+\"/.env\", override=True)\n",
    "credentials = Credentials(\n",
    "                url = os.getenv(\"WATSONX_URL\", \"https://us-south.ml.cloud.ibm.com\"),\n",
    "                api_key = os.getenv(\"WATSONX_APIKEY\", \"\")\n",
    "                )\n",
    "\n",
    "client = APIClient(credentials)\n",
    "\n",
    "project_id = os.getenv(\"WATSONX_PROJECT\", \"\")\n",
    "client.set.default_project(project_id)\n",
    "\n",
    "embeddings = Embeddings(\n",
    "    model_id=client.foundation_models.EmbeddingModels.MULTILINGUAL_E5_LARGE,\n",
    "    credentials=credentials,\n",
    "    project_id=project_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing a few sample rows with their embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_combined = df_shoes['COMBINED'].tolist()\n",
    "shoe_vectors = embeddings.embed_documents(texts=row_combined)\n",
    "df_shoes['EMBEDDING'] = shoe_vectors\n",
    "df_shoes['EMBEDDING'] = df_shoes['EMBEDDING'].apply(lambda x: '[' + ', '.join(map(str, x)) + ']')\n",
    "df_shoes.drop(['COMBINED'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_show = ['TYPE', 'MATERIAL', 'COLOR', 'WEATHER_RESISTANCE', 'ARCH_SUPPORT', 'EMBEDDING']\n",
    "df_shoes[cols_to_show].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_shoes.iloc[0]['EMBEDDING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shoes.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the shoes dataframe into a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shoes.to_csv(\n",
    "    'shoes-vectors.csv',\n",
    "    index=False,\n",
    "    quoting=csv.QUOTE_NONNUMERIC\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
